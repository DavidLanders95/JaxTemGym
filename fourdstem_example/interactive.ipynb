{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba812409",
   "metadata": {},
   "source": [
    "# Descan + STEM Overfocus procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60801cab",
   "metadata": {},
   "source": [
    "Suppose we want to calibriate and verify the experimental microscope parameters of a fourdstem dataset which suffers from descan error - \n",
    "\n",
    "This notebook shows that using three vacuum reference datasets, taken at three *known* camera lengths (e.g. calibrated with polycrystalline gold diffraction rings), one can characterise first the descan error, and semi-convergence angle of the beam. \n",
    "\n",
    "Then using a back reconstruction step with the known descan error and semi-convergence values, and the 4D stem experimental dataset, we can determine the scan step, scan rotation, detector flip and defocus values of the microscope system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7153eb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "from scipy.optimize import curve_fit\n",
    "import libertem.api as lt\n",
    "from libertem.udf.sum import SumUDF\n",
    "from libertem.udf.com import CoMUDF, RegressionOptions\n",
    "from libertem.udf.masks import ApplyMasksUDF\n",
    "from skimage.measure import label, regionprops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c962461e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import microscope_calibration.components as comp\n",
    "from microscope_calibration.model import ModelParameters\n",
    "from microscope_calibration.interactive import interactive_window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765afd56",
   "metadata": {},
   "source": [
    "Here load three vacuum reference datasets calculated with three known camera_lengths. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbca710e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = lt.Context.make_with(\"inline\")  # no parallelisation, good for debugging\n",
    "datasets = {\n",
    "    0.5: ctx.load(\"npy\", \"./fourdstem_array_0.5.npy\"),\n",
    "    1.0: ctx.load(\"npy\", \"./fourdstem_array_1.0.npy\"),\n",
    "    1.5: ctx.load(\"npy\", \"./fourdstem_array_1.5.npy\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56eec9fa",
   "metadata": {},
   "source": [
    "Just for visualisation, we start with a sum image of all dataset frames, and the CoM shift magnitude relative to the frame centre for each scan position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2c205e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3)\n",
    "\n",
    "px_shifts_matrix = {\n",
    "    0.5: None,\n",
    "    1.0: None,\n",
    "    1.5: None,\n",
    "}\n",
    "\n",
    "shifts = {\n",
    "    0.5: None,\n",
    "    1.0: None,\n",
    "    1.5: None,\n",
    "}\n",
    "\n",
    "distances = {\n",
    "    0.5: None,\n",
    "    1.0: None,\n",
    "    1.5: None,\n",
    "}\n",
    "\n",
    "com_r = {}\n",
    "com_udf = CoMUDF.with_params(regression=RegressionOptions.SUBTRACT_LINEAR)\n",
    "for i, (cl, ds) in enumerate(datasets.items()):\n",
    "    sum_res, com_res = ctx.run_udf(ds, [SumUDF(), com_udf])\n",
    "    com_r[cl] = com_res\n",
    "    axs[0, i].imshow(sum_res[\"intensity\"].data, cmap=\"gray\")\n",
    "    axs[0, i].set_title(f\"Sum cl={cl}\")\n",
    "    px_shifts_matrix[cl] = com_res[\"regression\"].data\n",
    "    shifts[cl] = com_res[\"raw_shifts\"].data\n",
    "    distances[cl] = np.hypot(shifts[cl][..., 0], shifts[cl][..., 1])\n",
    "\n",
    "vmax = max(np.max(shift) for shift in distances.values())\n",
    "for i, (cl, ds) in enumerate(datasets.items()):\n",
    "    distance = distances[cl]\n",
    "    axs[1, i].imshow(distance, vmin=0, vmax=vmax)\n",
    "    axs[1, i].set_title(f\"CoM shift cl={cl}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde08914",
   "metadata": {},
   "source": [
    "We can see that there is mose descan error at longer camera lengths, meaning we have an error dependent on the slope of the rays leaving the descanner.\n",
    "\n",
    "Now we have an estimate of the CoM shift for each dataset we can compute a point virtual detector image with the most basic kind of error compensation: Simply fitting a 3x3 affine transform matrix to the pixel shifts, and using that to registrate each disk back to the centre of the detector. The drawback is we must compute a new affine transform for each camera length, and we do not correct for astigmatism in the disks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394b5c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "sy, sx = ds.shape.sig.to_tuple()\n",
    "mask_px = sy // 2, sx // 2\n",
    "\n",
    "\n",
    "def mask_factory():\n",
    "    mask = np.zeros((sy, sx), dtype=np.float32)\n",
    "    mask[mask_px] = 1.0\n",
    "    return mask\n",
    "\n",
    "\n",
    "masks_udf = ApplyMasksUDF(\n",
    "    [mask_factory],\n",
    "    use_torch=False,\n",
    "    use_sparse=False,\n",
    "    mask_count=1,\n",
    ")\n",
    "\n",
    "fig, axs = plt.subplots(2, 3)\n",
    "\n",
    "for i, (cl, ds) in enumerate(datasets.items()):\n",
    "    masks_shifted_udf = ApplyMasksUDF(\n",
    "        [mask_factory],\n",
    "        use_torch=False,\n",
    "        use_sparse=False,\n",
    "        mask_count=1,\n",
    "        shifts=ApplyMasksUDF.aux_data(\n",
    "            np.round(com_r[cl][\"raw_shifts\"].data).astype(int),\n",
    "            dtype=int,\n",
    "            kind=\"nav\",\n",
    "            extra_shape=(2,),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    sum_res, com_res = ctx.run_udf(ds, [masks_udf, masks_shifted_udf])\n",
    "\n",
    "    axs[0, i].imshow(sum_res[\"intensity\"].data)\n",
    "    axs[0, i].set_title(f\"Point cl={cl}\")\n",
    "    axs[1, i].imshow(com_res[\"intensity\"].data)\n",
    "    axs[1, i].set_title(f\"Shifted point cl={cl}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e66ff72",
   "metadata": {},
   "source": [
    "As we can see, the descan compensation approximately corrects for the distortion of the scan grid, making the point image square, and independent of camera length."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35b7a62",
   "metadata": {},
   "source": [
    "We can now determine scan rotation, step and flip on one dataset, while ignoring the descan error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919d2d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = 1.0\n",
    "ds = datasets[cl]\n",
    "det_px_size = (0.004, 0.004)  # YX!\n",
    "pxshifts = px_shifts_matrix[cl]\n",
    "\n",
    "nav_shape = ds.shape.nav\n",
    "rand_nav_x, rand_nav_y = (\n",
    "    np.random.randint(0, nav_shape[0]),\n",
    "    np.random.randint(0, nav_shape[1]),\n",
    ")\n",
    "\n",
    "pick_a = ctx.create_pick_analysis(ds, rand_nav_x, rand_nav_y)\n",
    "frame = ctx.run(pick_a).intensity.raw_data\n",
    "shift = shifts[1.0][rand_nav_y, rand_nav_x]\n",
    "frame = np.roll(frame, -1 * shift, axis=(0, 1))\n",
    "radius = (\n",
    "    max(\n",
    "        regionprops(label(frame > frame.max() * 0.5)), key=lambda r: r.area\n",
    "    ).equivalent_diameter\n",
    "    / 2\n",
    ")\n",
    "semi_conv_guess = (radius * det_px_size[0]) / cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e5aa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_guesses\n",
    "model_parameters = ModelParameters(\n",
    "    **{\n",
    "        \"semi_conv\": float(semi_conv_guess),\n",
    "        \"defocus\": 0.02,  # Distance from the crossover to the sample\n",
    "        \"camera_length\": cl,  # Distance from the sample to the detector\n",
    "        \"scan_shape\": ds.shape.nav,  # YX!\n",
    "        \"det_shape\": ds.shape.sig,  # YX!\n",
    "        \"scan_step\": (0.0001, 0.0001),  # YX!\n",
    "        \"det_px_size\": det_px_size,  # YX!\n",
    "        \"scan_rotation\": 30.0,\n",
    "        \"descan_error\": np.zeros((12,)),\n",
    "        \"flip_y\": False,\n",
    "        \"px_shifts\": pxshifts,  # YX!\n",
    "    }\n",
    ")\n",
    "interactive_window(ctx, ds, model_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f11b18",
   "metadata": {},
   "source": [
    "We would have to determine the defocus of each dataset separately, unless we knew it was unchanged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971e057e",
   "metadata": {},
   "outputs": [],
   "source": [
    "flip_y = False\n",
    "semiconv = 0.1\n",
    "scan_rotation = 30\n",
    "defocus = 0.02\n",
    "scan_step = (0.0001, 0.0001)\n",
    "det_px_size = (0.004, 0.004)\n",
    "flip_y = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b88642d",
   "metadata": {},
   "source": [
    "With these parameters determined and more certainty on the input coordinate scan coordinates, we can then solve simultaneously on the three datasets to determine the descan error matrix that describes the microscope experiment. This descan error matrix will determine the propagation matrix of the microscope that describes the descan error dependance on camera length, and enable us to correct for astigmatism in the disks also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58113a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_coords = []\n",
    "det_coords = []\n",
    "b_vals = []\n",
    "for camera_length, ds in datasets.items():\n",
    "    crossover_z = jnp.zeros((1))\n",
    "    ScanGrid = comp.ScanGrid(\n",
    "        z=jnp.array([defocus]),\n",
    "        scan_step=scan_step,\n",
    "        scan_shape=ds.shape.nav.to_tuple(),\n",
    "        scan_rotation=scan_rotation,\n",
    "    )\n",
    "    scan_coords.append(ScanGrid.coords)\n",
    "    Detector = comp.Detector(\n",
    "        z=jnp.array(camera_length),\n",
    "        det_shape=ds.shape.sig.to_tuple(),\n",
    "        det_pixel_size=det_px_size,\n",
    "        flip_y=flip_y,\n",
    "    )\n",
    "    yx_px_det = com_r[camera_length][\"raw_com\"].data.reshape(-1, 2)\n",
    "    det_coords.append(np.stack(Detector.pixels_to_metres(yx_px_det.T), axis=1))\n",
    "    b_vals.append(camera_length - defocus)\n",
    "\n",
    "bvals = np.concatenate(\n",
    "    tuple(np.full((c.shape[0],), b) for b, c in zip(b_vals, scan_coords))\n",
    ")\n",
    "scan_coords = np.concatenate(scan_coords, axis=0)\n",
    "det_coords = np.concatenate(det_coords, axis=0)\n",
    "bvals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa75f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def descan_model(vars, Adx_dpos, Cdx_dslope, Ady_dpos, Cdy_dslope):\n",
    "    xin, yin, B = vars\n",
    "    return xin * (Adx_dpos + B * Cdx_dslope) + yin * (Ady_dpos + B * Cdy_dslope)\n",
    "\n",
    "\n",
    "# Take only N random samples from the data\n",
    "num_samples = 10000\n",
    "indices = np.random.choice(bvals.size, num_samples, replace=False)\n",
    "\n",
    "popt_x, pcov_x = curve_fit(\n",
    "    descan_model,\n",
    "    (scan_coords[:, 0][indices], scan_coords[:, 1][indices], bvals[indices]),\n",
    "    det_coords[:, 0][indices],\n",
    "    p0=np.zeros(4),\n",
    ")\n",
    "Axx, Cxx, Axy, Cxy = popt_x\n",
    "\n",
    "popt_y, pcov_y = curve_fit(\n",
    "    descan_model,\n",
    "    (scan_coords[:, 0][indices], scan_coords[:, 1][indices], bvals[indices]),\n",
    "    det_coords[:, 1][indices],\n",
    "    p0=np.zeros(4),\n",
    ")\n",
    "Ayx, Cyx, Ayy, Cyy = popt_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064f26b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nFit ABCD Values (with 5-sigma error):\")\n",
    "print(f\"Axx_dpos = {Axx:.2f} ± {5 * np.sqrt(pcov_x[0, 0]):.2e}\")\n",
    "print(f\"Axy_dpos = {Axy:.2f} ± {5 * np.sqrt(pcov_x[2, 2]):.2e}\")\n",
    "print(f\"Ayx_dpos = {Ayx:.2f} ± {5 * np.sqrt(pcov_y[0, 0]):.2e}\")\n",
    "print(f\"Ayy_dpos = {Ayy:.2f} ± {5 * np.sqrt(pcov_y[2, 2]):.2e}\")\n",
    "print(f\"Cxx_dslope = {Cxx:.2f} ± {5 * np.sqrt(pcov_x[1, 1]):.2e}\")\n",
    "print(f\"Cxy_dslope = {Cxy:.2f} ± {5 * np.sqrt(pcov_x[3, 3]):.2e}\")\n",
    "print(f\"Cyx_dslope = {Cyx:.2f} ± {5 * np.sqrt(pcov_y[1, 1]):.2e}\")\n",
    "print(f\"Cyy_dslope = {Cyy:.2f} ± {5 * np.sqrt(pcov_y[3, 3]):.2e}\")\n",
    "\n",
    "Axx, Ayy, Cxx, Cyy = (\n",
    "    8,\n",
    "    6,\n",
    "    -20,\n",
    "    -16,\n",
    ")  # Normal Descan Error terms Axx, Ayy, Cxx, Cyy in transfer matrix\n",
    "Axy, Ayx, Cxy, Cyx = (\n",
    "    12,\n",
    "    -14,\n",
    "    -12,\n",
    "    20,\n",
    ")  # Cross Descan Error terms Axy, Ayx, Cxy, Cyx in transfer matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c006c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = 1.0\n",
    "ds = datasets[cl]\n",
    "# initial_guesses\n",
    "model_parameters = {\n",
    "    \"semi_conv\": semiconv,\n",
    "    \"defocus\": defocus,  # Distance from the crossover to the sample\n",
    "    \"camera_length\": cl,  # Distance from the sample to the detector\n",
    "    \"scan_shape\": ds.shape.nav,  # YX!\n",
    "    \"det_shape\": ds.shape.sig,  # YX!\n",
    "    \"scan_step\": scan_step,  # YX!\n",
    "    \"det_px_size\": det_px_size,  # YX!\n",
    "    \"scan_rotation\": scan_rotation,\n",
    "    \"descan_error\": np.asarray([Axx - 1, Axy, Ayx, Ayy - 1, Cxx, Cxy, Cyx, Cyy]),\n",
    "    \"flip_y\": flip_y,\n",
    "    \"px_shifts\": None,  # YX!\n",
    "}\n",
    "interactive_window(ctx, ds, model_parameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temgym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
