{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba812409",
   "metadata": {},
   "source": [
    "# Descan + STEM Overfocus procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60801cab",
   "metadata": {},
   "source": [
    "Suppose we want to calibriate and verify the experimental microscope parameters of a fourdstem dataset which suffers from descan error - \n",
    "\n",
    "This notebook shows that using three vacuum reference datasets, taken at three *known* camera lengths (e.g. calibrated with polycrystalline gold diffraction rings), one can characterise first the descan error, and semi-convergence angle of the beam. \n",
    "\n",
    "Then using a back reconstruction step with the known descan error and semi-convergence values, and the 4D stem experimental dataset, we can determine the scan step, scan rotation, detector flip and defocus values of the microscope system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6895c945-cc50-4a82-8120-a9b6e7283cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "jax.config.update(\"jax_platform_name\", \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7153eb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "import jax.numpy as jnp\n",
    "from scipy.optimize import curve_fit\n",
    "import libertem.api as lt\n",
    "from libertem.udf.sum import SumUDF\n",
    "from libertem.udf.com import CoMUDF, RegressionOptions\n",
    "from libertem.udf.masks import ApplyMasksUDF\n",
    "from skimage.measure import label, regionprops\n",
    "from concurrent.futures import ProcessPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c962461e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import microscope_calibration.components as comp\n",
    "from microscope_calibration.model import ModelParameters\n",
    "from microscope_calibration.generate import generate_dataset_from_image\n",
    "from microscope_calibration.interactive import interactive_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209e17aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = lt.Context.make_with(\"inline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7731df7f",
   "metadata": {},
   "source": [
    "This notebook assumes you know the *pixel size* of your detector, and have acquired three overfocus dataset acquired at a *known camera lengths*, calibrated using some other method.\n",
    "\n",
    "To begin we will generate these data so that this notebook is standalone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729578e0",
   "metadata": {},
   "source": [
    "## 0 - Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4edd413",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image = plt.imread(r\"SilverFast_Resolution_Target_USAF_1951.png\")[:, :, 0]\n",
    "sample_image = sample_image[1:-1, 1:-1]\n",
    "sample_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c987706",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = ModelParameters(\n",
    "    semi_conv=0.1,\n",
    "    defocus=0.01,  # Distance from the crossover to the sample\n",
    "    camera_length=1.0,  # Distance from the point source to the detector\n",
    "    scan_shape=(32, 32),  # YX!\n",
    "    det_shape=(128, 128),  # YX!\n",
    "    scan_step=(0.0001, 0.0001),  # YX!\n",
    "    det_px_size=(0.004, 0.004),  # YX!\n",
    "    scan_rotation=33.,\n",
    "    descan_error=np.zeros((12,)),\n",
    "    flip_y=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71eb7f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "clengths = (0.5, 1.0, 1.5)\n",
    "with ProcessPoolExecutor(max_workers=3) as p:\n",
    "    futures = []\n",
    "    for cl in clengths:\n",
    "        _params = copy.deepcopy(params)\n",
    "        _params[\"camera_length\"] = cl\n",
    "        f = p.submit(generate_dataset_from_image, _params, sample_image, method=\"linear\", progress=False)\n",
    "        futures.append(f)\n",
    "    \n",
    "    for f, cl in zip(futures, clengths):\n",
    "        data = f.result()\n",
    "        datasets[cl] = ctx.load(\"memory\", data=data, num_partitions=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f09fff",
   "metadata": {},
   "source": [
    "## 1 - Determine approximate semiconvergence angle\n",
    "\n",
    "We can determine an approximate $\\alpha$ by measuring the radius of the transmitted beam in pixels, and using the pixel size and camera length to measure the angle of the triangle with origin at the point source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ed78a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "guesses = []\n",
    "for cl in datasets.keys():\n",
    "    det_px_size = min(params[\"det_px_size\"])\n",
    "    sy, sx = datasets[cl].shape.nav\n",
    "    pick_a = ctx.create_pick_analysis(datasets[cl], sx // 2, sy // 2)\n",
    "    frame = ctx.run(pick_a).intensity.raw_data\n",
    "    radius = (\n",
    "        max(\n",
    "            regionprops(label(frame > frame.max() * 0.5)), key=lambda r: r.area\n",
    "        ).equivalent_diameter\n",
    "        / 2\n",
    "    )\n",
    "    semi_conv_guess = float(np.atan2(radius * det_px_size, cl))\n",
    "    guesses.append(semi_conv_guess)\n",
    "    print(f\"Camera length: {cl}, Approximte semiconv: {semi_conv_guess:.3f}, True value {params['semi_conv']}\")\n",
    "\n",
    "semi_conv_guess = np.mean(guesses)\n",
    "print(f\"Average approximte semiconv: {semi_conv_guess:.3f}, True value {params['semi_conv']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21997f0",
   "metadata": {},
   "source": [
    "## 2 - Visualise descan error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56eec9fa",
   "metadata": {},
   "source": [
    "Just for visualisation, we start with a sum image of all dataset frames, and the CoM shift magnitude relative to the frame centre for each scan position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2c205e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3)\n",
    "\n",
    "com_r = {}\n",
    "com_udf = CoMUDF.with_params()\n",
    "for i, (cl, ds) in enumerate(datasets.items()):\n",
    "    sum_res, com_res = ctx.run_udf(ds, [SumUDF(), com_udf])\n",
    "    com_r[cl] = com_res\n",
    "    axs[0, i].imshow(sum_res[\"intensity\"].data, cmap=\"gray\")\n",
    "    axs[0, i].set_title(f\"Sum cl={cl}\")\n",
    "\n",
    "for i, (cl, ds) in enumerate(datasets.items()):\n",
    "    axs[1, i].imshow(com_r[cl][\"magnitude\"].data)\n",
    "    axs[1, i].set_title(f\"CoM shift cl={cl}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde08914",
   "metadata": {},
   "source": [
    "We can see that there is mose descan error at longer camera lengths, meaning we have an error dependent on the slope of the rays leaving the descanner.\n",
    "\n",
    "## 3 - Determine parameters ignoring descan error\n",
    "\n",
    "Even in the presence of descan error, we can reconstruct a single dataset to determine the scan geometry and defocus. The result will be distorted, but should still be sharp when the right parameters are found. We start from a scan step which is know approximately, but with no knowledge of the scan step or defocus value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e242ae4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "guess_params = copy.deepcopy(params)\n",
    "cl = 1.0\n",
    "guess_params[\"camera_length\"] = cl\n",
    "guess_params[\"semi_conv\"] = semi_conv_guess\n",
    "guess_params[\"defocus\"] = 0.\n",
    "guess_params[\"scan_step\"] = np.asarray(guess_params[\"scan_step\"]) * np.random.uniform(0.8, 1.2)\n",
    "guess_params[\"scan_rotation\"] = 0.\n",
    "interactive_window(ctx, datasets[cl], guess_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c393e7a",
   "metadata": {},
   "source": [
    "\n",
    "Now we have an estimate of the CoM shift for each dataset we can compute a point virtual detector image with the most basic kind of error compensation: Simply fitting a 3x3 affine transform matrix to the pixel shifts, and using that to registrate each disk back to the centre of the detector. The drawback is we must compute a new affine transform for each camera length, and we do not correct for astigmatism in the disks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394b5c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "sy, sx = ds.shape.sig.to_tuple()\n",
    "mask_px = sy // 2, sx // 2\n",
    "\n",
    "\n",
    "def mask_factory():\n",
    "    mask = np.zeros((sy, sx), dtype=np.float32)\n",
    "    mask[mask_px] = 1.0\n",
    "    return mask\n",
    "\n",
    "\n",
    "masks_udf = ApplyMasksUDF(\n",
    "    [mask_factory],\n",
    "    use_torch=False,\n",
    "    use_sparse=False,\n",
    "    mask_count=1,\n",
    ")\n",
    "\n",
    "fig, axs = plt.subplots(2, 3)\n",
    "\n",
    "for i, (cl, ds) in enumerate(datasets.items()):\n",
    "    masks_shifted_udf = ApplyMasksUDF(\n",
    "        [mask_factory],\n",
    "        use_torch=False,\n",
    "        use_sparse=False,\n",
    "        mask_count=1,\n",
    "        shifts=ApplyMasksUDF.aux_data(\n",
    "            np.round(com_r[cl][\"raw_shifts\"].data).astype(int),\n",
    "            dtype=int,\n",
    "            kind=\"nav\",\n",
    "            extra_shape=(2,),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    sum_res, com_res = ctx.run_udf(ds, [masks_udf, masks_shifted_udf])\n",
    "\n",
    "    axs[0, i].imshow(sum_res[\"intensity\"].data)\n",
    "    axs[0, i].set_title(f\"Point cl={cl}\")\n",
    "    axs[1, i].imshow(com_res[\"intensity\"].data)\n",
    "    axs[1, i].set_title(f\"Shifted point cl={cl}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e66ff72",
   "metadata": {},
   "source": [
    "As we can see, the descan compensation approximately corrects for the distortion of the scan grid, making the point image square, and independent of camera length."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35b7a62",
   "metadata": {},
   "source": [
    "We can now determine scan rotation, step and flip on one dataset, while ignoring the descan error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919d2d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = 1.0\n",
    "ds = datasets[cl]\n",
    "det_px_size = (0.004, 0.004)  # YX!\n",
    "pxshifts = px_shifts_matrix[cl]\n",
    "\n",
    "nav_shape = ds.shape.nav\n",
    "rand_nav_x, rand_nav_y = (\n",
    "    np.random.randint(0, nav_shape[0]),\n",
    "    np.random.randint(0, nav_shape[1]),\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e5aa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_guesses\n",
    "model_parameters = ModelParameters(\n",
    "    **{\n",
    "        \"semi_conv\": float(semi_conv_guess),\n",
    "        \"defocus\": 0.02,  # Distance from the crossover to the sample\n",
    "        \"camera_length\": cl,  # Distance from the sample to the detector\n",
    "        \"scan_shape\": ds.shape.nav,  # YX!\n",
    "        \"det_shape\": ds.shape.sig,  # YX!\n",
    "        \"scan_step\": (0.0001, 0.0001),  # YX!\n",
    "        \"det_px_size\": det_px_size,  # YX!\n",
    "        \"scan_rotation\": 30.0,\n",
    "        \"descan_error\": np.zeros((12,)),\n",
    "        \"flip_y\": False,\n",
    "        \"px_shifts\": pxshifts,  # YX!\n",
    "    }\n",
    ")\n",
    "interactive_window(ctx, ds, model_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f11b18",
   "metadata": {},
   "source": [
    "We would have to determine the defocus of each dataset separately, unless we knew it was unchanged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971e057e",
   "metadata": {},
   "outputs": [],
   "source": [
    "flip_y = False\n",
    "semiconv = 0.1\n",
    "scan_rotation = 30\n",
    "defocus = 0.02\n",
    "scan_step = (0.0001, 0.0001)\n",
    "det_px_size = (0.004, 0.004)\n",
    "flip_y = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b88642d",
   "metadata": {},
   "source": [
    "With these parameters determined and more certainty on the input coordinate scan coordinates, we can then solve simultaneously on the three datasets to determine the descan error matrix that describes the microscope experiment. This descan error matrix will determine the propagation matrix of the microscope that describes the descan error dependance on camera length, and enable us to correct for astigmatism in the disks also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58113a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_coords = []\n",
    "det_coords = []\n",
    "b_vals = []\n",
    "for camera_length, ds in datasets.items():\n",
    "    crossover_z = jnp.zeros((1))\n",
    "    ScanGrid = comp.ScanGrid(\n",
    "        z=jnp.array([defocus]),\n",
    "        scan_step=scan_step,\n",
    "        scan_shape=ds.shape.nav.to_tuple(),\n",
    "        scan_rotation=scan_rotation,\n",
    "    )\n",
    "    scan_coords.append(ScanGrid.coords)\n",
    "    Detector = comp.Detector(\n",
    "        z=jnp.array(camera_length),\n",
    "        det_shape=ds.shape.sig.to_tuple(),\n",
    "        det_pixel_size=det_px_size,\n",
    "        flip_y=flip_y,\n",
    "    )\n",
    "    yx_px_det = com_r[camera_length][\"raw_com\"].data.reshape(-1, 2)\n",
    "    det_coords.append(np.stack(Detector.pixels_to_metres(yx_px_det.T), axis=1))\n",
    "    b_vals.append(camera_length - defocus)\n",
    "\n",
    "bvals = np.concatenate(\n",
    "    tuple(np.full((c.shape[0],), b) for b, c in zip(b_vals, scan_coords))\n",
    ")\n",
    "scan_coords = np.concatenate(scan_coords, axis=0)\n",
    "det_coords = np.concatenate(det_coords, axis=0)\n",
    "bvals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa75f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def descan_model(vars, Adx_dpos, Cdx_dslope, Ady_dpos, Cdy_dslope):\n",
    "    xin, yin, B = vars\n",
    "    return xin * (Adx_dpos + B * Cdx_dslope) + yin * (Ady_dpos + B * Cdy_dslope)\n",
    "\n",
    "\n",
    "# Take only N random samples from the data\n",
    "num_samples = 10000\n",
    "indices = np.random.choice(bvals.size, num_samples, replace=False)\n",
    "\n",
    "popt_x, pcov_x = curve_fit(\n",
    "    descan_model,\n",
    "    (scan_coords[:, 0][indices], scan_coords[:, 1][indices], bvals[indices]),\n",
    "    det_coords[:, 0][indices],\n",
    "    p0=np.zeros(4),\n",
    ")\n",
    "Axx, Cxx, Axy, Cxy = popt_x\n",
    "\n",
    "popt_y, pcov_y = curve_fit(\n",
    "    descan_model,\n",
    "    (scan_coords[:, 0][indices], scan_coords[:, 1][indices], bvals[indices]),\n",
    "    det_coords[:, 1][indices],\n",
    "    p0=np.zeros(4),\n",
    ")\n",
    "Ayx, Cyx, Ayy, Cyy = popt_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064f26b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nFit ABCD Values (with 5-sigma error):\")\n",
    "print(f\"Axx_dpos = {Axx:.2f} ± {5 * np.sqrt(pcov_x[0, 0]):.2e}\")\n",
    "print(f\"Axy_dpos = {Axy:.2f} ± {5 * np.sqrt(pcov_x[2, 2]):.2e}\")\n",
    "print(f\"Ayx_dpos = {Ayx:.2f} ± {5 * np.sqrt(pcov_y[0, 0]):.2e}\")\n",
    "print(f\"Ayy_dpos = {Ayy:.2f} ± {5 * np.sqrt(pcov_y[2, 2]):.2e}\")\n",
    "print(f\"Cxx_dslope = {Cxx:.2f} ± {5 * np.sqrt(pcov_x[1, 1]):.2e}\")\n",
    "print(f\"Cxy_dslope = {Cxy:.2f} ± {5 * np.sqrt(pcov_x[3, 3]):.2e}\")\n",
    "print(f\"Cyx_dslope = {Cyx:.2f} ± {5 * np.sqrt(pcov_y[1, 1]):.2e}\")\n",
    "print(f\"Cyy_dslope = {Cyy:.2f} ± {5 * np.sqrt(pcov_y[3, 3]):.2e}\")\n",
    "\n",
    "Axx, Ayy, Cxx, Cyy = (\n",
    "    8,\n",
    "    6,\n",
    "    -20,\n",
    "    -16,\n",
    ")  # Normal Descan Error terms Axx, Ayy, Cxx, Cyy in transfer matrix\n",
    "Axy, Ayx, Cxy, Cyx = (\n",
    "    12,\n",
    "    -14,\n",
    "    -12,\n",
    "    20,\n",
    ")  # Cross Descan Error terms Axy, Ayx, Cxy, Cyx in transfer matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c006c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = 1.0\n",
    "ds = datasets[cl]\n",
    "# initial_guesses\n",
    "model_parameters = {\n",
    "    \"semi_conv\": semiconv,\n",
    "    \"defocus\": defocus,  # Distance from the crossover to the sample\n",
    "    \"camera_length\": cl,  # Distance from the sample to the detector\n",
    "    \"scan_shape\": ds.shape.nav,  # YX!\n",
    "    \"det_shape\": ds.shape.sig,  # YX!\n",
    "    \"scan_step\": scan_step,  # YX!\n",
    "    \"det_px_size\": det_px_size,  # YX!\n",
    "    \"scan_rotation\": scan_rotation,\n",
    "    \"descan_error\": np.asarray([Axx - 1, Axy, Ayx, Ayy - 1, Cxx, Cxy, Cyx, Cyy]),\n",
    "    \"flip_y\": flip_y,\n",
    "    \"px_shifts\": None,  # YX!\n",
    "}\n",
    "interactive_window(ctx, ds, model_parameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temgym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
